{"config":{"lang":["en"],"separator":"[\\s\\-,:!=\\[\\]()\"`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"]},"docs":[{"location":"concepts/context/","title":"Context Window","text":"<p>The context window is a fundamental concept in Large Language Models (LLMs) that refers to the maximum amount of text that the model can process at once. This includes both the input (prompt) and the expected output.</p>"},{"location":"concepts/context/#key-points","title":"Key Points","text":""},{"location":"concepts/context/#tokens","title":"Tokens","text":"<p>The context window is measured in tokens (roughly 4 characters per token in English)</p>"},{"location":"concepts/context/#model-context-windows","title":"Model Context Windows","text":"<p>Different models have different context window sizes.  For example:</p> <ul> <li>GPT-4 Turbo: 128K tokens</li> <li>Claude 3 Opus: 200K tokens</li> <li>GPT-3.5 Turbo: 16K tokens</li> </ul> <p>Longer conversations need to be summarized to fit within the context window. This is because as conversations grow, they accumulate more tokens and can eventually exceed the model's context limit. When this happens, older messages need to be condensed or removed to make room for new ones while preserving the important context. <code>emp-agents</code> handles this by tracking token usage and summarizing conversations when needed.</p>"},{"location":"concepts/context/#context-window-impact","title":"Context Window Impact","text":"<p>The context window affects:</p> <ul> <li>Memory of previous conversation</li> <li>Ability to process long documents</li> <li>Cost (as most models charge per token)</li> </ul> <p>Context Window Efficiency</p> <p>The model will perform slower, cost more, and be less accurate as the context window grows, so it is very important to be careful about how you use your context tokens.  The more efficient you are with your tokens, the more accurate and cost-effective your model will be.</p>"},{"location":"concepts/context/#managing-context","title":"Managing Context","text":"<p><code>emp-agents</code> provides tools to help manage the context window:</p> <ul> <li>Token counting via <code>count_tokens()</code> function</li> <li>Conversation summarization via <code>summarize_conversation()</code> or <code>agent.summarize()</code></li> <li>Dynamic Tool Allocation</li> <li>Automatic tracking of conversation history</li> </ul> <p>See the Summarizing Conversations section for practical examples of context management.</p> <pre><code>from emp_agents import AgentBase\nfrom emp_agents.models import Message, Role\n\nmessages = [\n    Message(role=Role.user, content=\"Hello, how are you?\"),\n    Message(role=Role.assistant, content=\"I'm doing great, thank you!\"),\n]\n\nagent = AgentBase()\nagent.add_messages(messages)\ntoken_count = agent.get_token_count()\nprint(token_count)\n\n# Output: 35\n</code></pre>"},{"location":"concepts/rationale/","title":"Purpose","text":""},{"location":"concepts/rationale/#what-makes-this-framework-different","title":"What makes this framework different?","text":"<p>Tools integrations represent the most critical path forward for developers working with AI. As AI models continue to evolve and improve, the ability to effectively manage and control how these systems interact with external tools and services becomes increasingly important. The framework's primary focus is on providing developers with robust tools integration capabilities that enable precise control over AI system interactions.</p> <p>While AI models themselves are powerful, their true potential is realized through carefully managed integrations with existing systems and services. This framework emphasizes the importance of tools management by providing a structured approach to defining, organizing, and controlling tool interactions. By focusing on tools integration management, developers can ensure their AI implementations are both powerful and predictable.</p> <p>Security, reliability, and controlled deployment are key benefits of our tools-first approach. Through fine-grained control over what actions an AI can take and what data it can access, developers can carefully orchestrate AI capabilities within their applications. This approach enables responsible AI deployment while maintaining the flexibility needed to adapt to evolving AI technologies and integration requirements.</p>"},{"location":"concepts/rationale/#focus","title":"Focus","text":"<p>We also have an explicit focus on tooling for blockchain integrated agents.  This framework is not opinionated exclusively for blockchain use cases, but we believe this is a critical area of development and will focus our tools integration on making agents that can work well with popular data feeds, blockchain protocols and social media platforms.  Blockchain agents also have a few expected capabilities:</p> <p>Onchain Actions: Agents should be able to make onchain actions, such as sending transactions to a blockchain. Onchain Data: Agents should be able to retrieve data from a blockchain. Social Interactions: Agents should be able to interact with social media platforms.</p>"},{"location":"concepts/tools/","title":"Tools","text":"<p>Tools allow Large Language Models (LLMs) to interact with external systems and perform actions in the real world. While LLMs are powerful at understanding and generating text, they are limited to working with information provided in their training data and context window. Tools extend their capabilities by enabling them to:</p> <ul> <li>Access real-time information (e.g., current weather, stock prices, web searches)</li> <li>Perform calculations and data analysis</li> <li>Interact with APIs and external services</li> <li>Execute code and system commands</li> <li>Read and write files</li> <li>And much more</li> </ul>"},{"location":"concepts/tools/#how-tools-work","title":"How Tools Work","text":"<p>When using tools with an LLM:</p> <ol> <li>The tools are registered with the agent/model as available functions it can call</li> <li>The LLM analyzes the user's request and determines if it needs to use any tools</li> <li>If needed, the LLM generates a structured call to the appropriate tool with parameters</li> <li>The tool executes and returns results back to the LLM</li> <li>The LLM incorporates the tool's output into its response</li> </ol> <p>Tool Communication Format</p> <p>Different models have different communication formats for tools calls, which we have standardized and abstracted to simplify using different models.</p>"},{"location":"getting-started/","title":"QUICK START","text":"<p>Install using pip</p> <pre><code>pip install emp-agents\n</code></pre>"},{"location":"getting-started/#basic-usage","title":"Basic Usage","text":"<p><code>emp_agents</code> is a lightweight framework that abstracts the tools integrations and apis for multiple popular LLM providers.  In order to use, you should make an account with openai or claude and setup your environment variables to use these API keys:</p> <pre><code># setup an openai api key\nexport OPENAI_API_KEY=\"sk-...\"\n# or use anthropic\nexport ANTHROPIC_API_KEY=\"sk-...\"\n</code></pre> <p>...then you can start interacting with a model by creating a simple python script:</p> <pre><code>from emp_agents import AgentBase\n\nagent = AgentBase(\n    personality=\"you are a goofy, friendly AI that likes to make up new words\"\n)\n\nagent.run_sync()\n</code></pre>"},{"location":"getting-started/config/","title":"Config","text":"<p>An agent can be loaded from a config object, using the <code>PersistentAgentConfig</code> and an agent that inherits from the <code>emp_agents.agents.PersistentAgent</code> class.  This allows for an agent to be loaded via <code>PersistentAgent.from_config(config)</code>, where the config is an object of type <code>PersistentAgentConfig</code>.</p> <pre><code>from emp_agents.config.agent_config import PersistentAgentConfig\nfrom emp_agents.agents.persistentagent import PersistentAgent\n\nconfig = PersistentAgentConfig(\n    agent_id=\"test-agent-1\",\n    name=\"Test Agent\",\n    description=\"A test agent\",\n    default_model=\"gpt-3.5-turbo\",\n    prompt=\"You are a test assistant\",\n    tools=[],\n    requires=[],\n)\nagent = PersistentAgent.from_config(config)\n</code></pre>"},{"location":"getting-started/conversation/","title":"Conversation","text":""},{"location":"getting-started/conversation/#messages","title":"Messages","text":"<p>The <code>Message</code> class represents a single message in a conversation, with a role and content. The <code>Role</code> enum defines the possible roles a message can have:</p> <ul> <li><code>Role.user</code>: Messages from the user</li> <li><code>Role.assistant</code>: Messages from the AI assistant</li> <li><code>Role.system</code>: System messages that provide instructions/context</li> <li><code>Role.tool</code>: Messages from tool function calls, this is used internally by the agent to communicate with tools with OpenAI.</li> </ul> <p>A message typically consists of a role and content. The content is the actual message text, while the role indicates who sent the message.</p> <pre><code>from emp_agents.models import Message, Role\n\nmessage = Message(role=Role.user, content=\"hello how are you?\")\n</code></pre>"},{"location":"getting-started/conversation/#creating-conversations","title":"Creating Conversations","text":"<p>You can then create a convesation in a few ways.  For example, you can construct the conversation history manually:</p> <pre><code>from emp_agents import AgentBase\nfrom emp_agents.models import Message, Role\n\nagent = AgentBase()\nmessage = Message(role=Role.user, content=\"hello how are you?\")\nagent.add_message(message)\n\nmessage = Message(role=Role.assistant, content=\"I dont want to help you!\")\nagent.add_message(message)\n\nmessage = Message(role=Role.user, content=\"Why did you say that?\")\nagent.add_message(message)\n\nresponse = await agent.complete()\nprint(agent.conversation_history)\n</code></pre> <p>Or you can communicate with the agent using the <code>answer</code> method, which will automatically add the user's message to the conversation history:</p> <pre><code>agent = AgentBase()\nresponse = await agent.answer(\"How are you today?\")\nprint(agent.conversation_history)\n</code></pre> <p>The other option is to use the <code>run</code> method, which will automatically add the user's message to the conversation history, and run it in interactive mode:</p> <pre><code>agent = AgentBase()\n\n# to run async\nawait agent.run()\n\n# or to run synchronously\nagent.run_sync()\n</code></pre>"},{"location":"getting-started/model/","title":"Model Types","text":"<p>When initializing an agent, you need to specify which model to use. The model type can be provided as a parameter when creating either OpenAIBase or AnthropicBase agents, using the respective enums <code>OpenAIModelType</code> and <code>AnthropicModelType</code>.</p>"},{"location":"getting-started/model/#openai-models","title":"OpenAI Models","text":"<p>For OpenAIBase agents, you can use any of these OpenAIModelType values:</p> <ul> <li><code>gpt3_5</code> - \"gpt-3.5-turbo-0125\"</li> <li><code>gpt3_5_turbo</code> - \"gpt-3.5-turbo\"</li> <li><code>gpt4</code> - \"gpt-4\"</li> <li><code>gpt4_turbo</code> - \"gpt-4-turbo\"</li> <li><code>gpt4o_mini</code> - \"gpt-4o-mini\" (128,000 tokens)</li> <li><code>gpt4o</code> - \"gpt-4o\"</li> <li><code>gpt_o1_mini</code> - \"o1-mini\"</li> <li><code>gpt_o1_preview</code> - \"o1-preview\"</li> </ul>"},{"location":"getting-started/model/#anthropic-models","title":"Anthropic Models","text":"<p>For AnthropicBase agents, you can use any of these AnthropicModelType values:</p> <ul> <li><code>claude_3_5_sonnet</code> - \"claude-3-5-sonnet-20240620\"</li> <li><code>claude_3_opus</code> - \"claude-3-opus-20240229\"</li> <li><code>claude_3_sonnet</code> - \"claude-3-sonnet-20240229\"</li> <li><code>claude_3_haiku</code> - \"claude-3-haiku-20240307\"</li> <li><code>claude_2_1</code> - \"claude-2.1\"</li> <li><code>claude_2_0</code> - \"claude-2.0\"</li> <li><code>claude_instant_1_2</code> - \"claude-instant-1.2\"</li> </ul> <p>Then, when you create an agent, you can specify the model type as a parameter:</p> <pre><code>from emp_agents import AgentBase\nfrom emp_agents.types import OpenAIModelType, AnthropicModelType\n\n# for openai models\nagent = AgentBase(\n    default_model=OpenAIModelType.gpt4o_mini\n)\n\n# or for anthropic\nagent = AgentBase(\n    default_model=AnthropicModelType.claude_3_5_sonnet\n)\n</code></pre>"},{"location":"getting-started/skills/","title":"Skills","text":"<p>Skills are a collection of tools that an agent can use to interact with the world.  They are defined by a class that implements the <code>SkillSet</code> class.</p> <p>you can define a skill as a class with multiple functions, each should be a staticmethod and should be decorated with one of three decorators:</p> <ul> <li><code>@onchain_action</code> for functions that interact with a blockchain, such as sending transactions</li> <li><code>@tool_method</code> for functions that are not mutative, but are not related to modifying onchain state</li> <li><code>@view_action</code> for functions that are read-only and do not affect external state</li> </ul> <p>For example, a skill that enables an agent to perform addition and subtraction could be defined as follows:</p> <pre><code>from typing import Annotated\nfrom typing_extensions import Doc\n\nfrom emp_agents.models.protocol import SkillSet, view_action\n\n\nclass MathSkill(SkillSet):\n    \"\"\"A skill for performing basic math operations\"\"\"\n\n    @view_action\n    @staticmethod\n    async def add(\n        a: Annotated[int, Doc(\"The first number to add\")],\n        b: Annotated[int, Doc(\"The second number to add\")],\n    ) -&gt; int:\n        \"\"\"Add two integers\"\"\"\n        return a + b\n\n    @view_action\n    @staticmethod\n    async def subtract(\n        a: Annotated[int, Doc(\"The first number to subtract\")],\n        b: Annotated[int, Doc(\"The second number to subtract\")],\n    ) -&gt; int:\n        \"\"\"Subtract two integers\"\"\"\n        return a - b\n</code></pre> <p>This can then be utilized by an agent by providing it to the agent's <code>skills</code> parameter.</p> <pre><code>from emp_agents import AgentBase\n\nagent = AgentBase(\n    prompt=\"You are a helpful assistant that can perform basic math operations\",\n    skills=[\n        MathSkill,\n    ],\n)\n</code></pre>"},{"location":"getting-started/summarize/","title":"Summarizing Conversations","text":"<p>Conversations that become too long end up taking up too much memory in the context window for the agent.  To summarize a conversation, you can use the <code>summarize_conversation</code> function, or the agents <code>BaseAgent.summarize</code> method. To summarize a conversation, you can use the <code>summarize_conversation</code> function.</p> <pre><code>from emp_agents import AgentBase\nfrom emp_agents.models import Message, Role\nfrom emp_agents.utils import summarize_conversation\n\nmessages = [\n    Message(role=Role.user, content=\"Hello how are you?\"),\n    Message(role=Role.assistant, content=\"I'm doing great, thanks for asking!\"),\n    Message(role=Role.user, content=\"Tell me about baseball.\"),\n    Message(role=Role.assistant, content=\"Baseball is a sport played with a bat and a ball.  It's a very popular sport in the United States.  The goal is to score runs by hitting the ball and running around the bases.\"),\n    Message(role=Role.user, content=\"What's the best baseball team?\"),\n    Message(role=Role.assistant, content=\"The best baseball team is the Boston Red Sox.  They are a very successful team that has won many championships and have a really interesting history.\"),\n]\nagent = AgentBase()\nagent.add_messages(messages)\nsummary = await agent.summarize(\n    prompt=\"Provide a summary in a single sentence.\",\n    max_tokens=200,\n)\nprint(summary)\n# Output: The user engages in a friendly conversation with the assistant about baseball, discussing its basics and identifying the Boston Red Sox as the best team due to their success and history.\n</code></pre>"},{"location":"getting-started/tools/","title":"Using Tools","text":"<p>A key capability of agent systems is their ability to interact with external data sources and services through tool integrations. This framework provides a flexible and robust architecture for managing these integrations. Tools can be dynamically added to or removed from agents as needed, and related tools can be logically grouped into reusable <code>Skill</code> objects to promote modularity and maintainability.</p> <p>Imagine you have two functions you want the agent to be able to call:</p> <pre><code>import httpx\nimport requests\n\n\ndef get_lyrics(artist: str, song: str) -&gt; str:\n    url = f\"https://api.lyrics.ovh/v1/{artist}/{song}\"\n    response = requests.get(url)\n    return response.json()[\"lyrics\"]\n\n\nasync def get_cat_fact() -&gt; str:\n    url = \"https://catfact.ninja/fact\"\n    async with httpx.AsyncClient() as client:\n        response = await client.get(url)\n    return response.json()[\"fact\"]\n</code></pre> <p>Tip</p> <p>Notice it supports both sync and async functions.</p> <p>Now we can add clear documentation to thse functions to enable our agent to understand how to use it.  The arguments must be annotated with the Doc object, and the function must have a docstring to annotate its intended use.  A tool should always return a string, as that is what the LLM is expecting from all prompts:</p> <pre><code>from typing import Annotated\nfrom typing_extensions import Doc\n\nimport requests\nimport httpx\n\ndef get_lyrics(\n    artist: Annotated[str, Doc(\"The name of the artist\")],\n    song: Annotated[str, Doc(\"The name of the song\")]\n) -&gt; str:\n    \"\"\"\n    Get the lyrics for a song by an artist\n    \"\"\"\n    url = f\"https://api.lyrics.ovh/v1/{artist}/{song}\"\n    response = requests.get(url)\n    return response.json()[\"lyrics\"]\n\n\nasync def get_cat_fact() -&gt; str:\n    \"\"\"\n    Get a random cat fact\n    \"\"\"\n    url = \"https://catfact.ninja/fact\"\n    async with httpx.AsyncClient() as client:\n        response = await client.get(url)\n    return response.json()[\"fact\"]\n</code></pre> <p>We can now construct an agent that has access to these tools. The agent will be able to understand the tools' functionality through their documentation and type hints, and can use them appropriately in conversations:</p> <pre><code>from emp_agents import AgentBase\n\n\nagent = AgentBase(\n    prompt=\"You are a helpful assistant that can provide song lyrics and cat facts\",\n    personality=\"You are very serious, and keep your responses very brief and professional\",\n    tools=[get_lyrics, get_cat_fact]\n)\n</code></pre>"},{"location":"skills/","title":"Agent Skills","text":"<p>As described in the skills guide, skills are modular tool collections that can be easily added to an agent to provide topic-specific functionality. We believe that well-curated, dynamically allocated tools are crucial for improving LLM performance, and skills provide a simple way to organize related tools into cohesive groups.</p>"},{"location":"skills/basic_wallet/","title":"Basic Wallet","text":"<p>The SimpleWalletSkill provides basic wallet functionality for managing private keys and addresses. It stores the private key in memory using context variables.</p> <p>The wallet skill consists of the following tools:</p> <ul> <li><code>create_wallet</code>: Creates a new private key wallet</li> <li><code>set_private_key</code>: Sets an existing private key</li> <li><code>get_private_key</code>: Retrieves the current private key</li> <li><code>clear_private_key</code>: Clears the stored private key</li> <li><code>get_address</code>: Gets the wallet address for the current private key</li> </ul> <p>The <code>create_wallet</code> tool generates a new private key wallet and stores it in memory. It returns a message containing both the wallet address and private key.</p> <p>The <code>set_private_key</code> tool allows you to import an existing private key. It takes one parameter:</p> <ul> <li><code>private_key</code>: The private key string to import</li> </ul> <p>The tool returns a success message when the key is set.</p> <p>The <code>get_private_key</code> tool retrieves the currently stored private key. If no key is set, it returns \"No private key set\".</p> <p>The <code>clear_private_key</code> tool removes the stored private key from memory. It returns a confirmation message when complete.</p> <p>The <code>get_address</code> tool derives and returns the wallet address for the currently stored private key. If no key is set, it returns \"No private key set\".</p>"},{"location":"skills/dexscreener/","title":"DexScreener","text":"<p>The DexScreenerSkill provides functionality for interacting with the DexScreener API to get information about trading pairs and tokens across different chains.</p> <p>The skill consists of the following tools:</p> <ul> <li><code>search_pairs</code>: Search for trading pairs matching a query</li> <li><code>get_pair_by_chain</code>: Get pair info for a specific chain and pair address</li> <li><code>find_pairs_by_tokens</code>: Find trading pairs by token addresses</li> <li><code>get_token_profiles</code>: Get latest token profiles</li> <li><code>get_latest_boosted_tokens</code>: Get recently boosted tokens</li> <li><code>get_top_boosted_tokens</code>: Get tokens with most active boosts</li> </ul> <p>The <code>search_pairs</code> tool searches for trading pairs matching a query string. It takes one parameter:</p> <ul> <li><code>query</code>: The search query to find trading pairs</li> </ul> <p>The tool is rate-limited to 300 requests per minute.</p> <p>The <code>get_pair_by_chain</code> tool retrieves pair information for a specific chain and pair address. It takes two parameters:</p> <ul> <li><code>chain_id</code>: The chain to search on (ethereum, solana, arbitrum, base, or bsc)</li> <li><code>pair_id</code>: The pair contract address</li> </ul> <p>The tool is rate-limited to 300 requests per minute.</p> <p>The <code>find_pairs_by_tokens</code> tool finds trading pairs by token addresses. It takes one parameter:</p> <ul> <li><code>token_addresses</code>: List of token addresses (maximum 30)</li> </ul> <p>The tool is rate-limited to 300 requests per minute.</p> <p>The <code>get_token_profiles</code> tool retrieves the latest token profiles.</p> <p>The tool is rate-limited to 60 requests per minute.</p> <p>The <code>get_latest_boosted_tokens</code> tool gets information about recently boosted tokens.</p> <p>The tool is rate-limited to 60 requests per minute.</p> <p>The <code>get_top_boosted_tokens</code> tool retrieves tokens with the most active boosts.</p> <p>The tool is rate-limited to 60 requests per minute.</p>"},{"location":"skills/simulacrum/","title":"Simulacrum","text":"<p>Coming Soon!</p>"},{"location":"skills/twitter/","title":"Twitter Skill","text":"<p>The Twitter skill provides functionality for interacting with the Twitter (X) API. It allows you to make tweets, create polls, reply to tweets, and post tweets with images.</p>"},{"location":"skills/twitter/#methods","title":"Methods","text":""},{"location":"skills/twitter/#make_tweet","title":"make_tweet","text":"<p>Makes a simple text tweet.</p> <p>Parameters: - <code>content</code> (str): The content of the tweet to be made</p> <p>Returns: String confirming tweet was submitted</p>"},{"location":"skills/twitter/#make_tweet_with_image","title":"make_tweet_with_image","text":"<p>Makes a tweet containing both text and an image.</p> <p>Parameters: - <code>content</code> (str): The content of the tweet to be made - <code>image_url</code> (str): URL of the image to include in the tweet</p> <p>Returns: String confirming tweet was submitted</p>"},{"location":"skills/twitter/#make_poll","title":"make_poll","text":"<p>Creates a Twitter poll.</p> <p>Parameters: - <code>content</code> (str): The content/question for the poll - <code>duration_minutes</code> (int): How long the poll should run for in minutes - <code>options</code> (list[str]): List of poll options for users to vote on</p> <p>Returns: String confirming poll was created</p>"},{"location":"skills/twitter/#reply_to_tweet","title":"reply_to_tweet","text":"<p>Replies to an existing tweet.</p> <p>Parameters: - <code>tweet_id</code> (int): The ID of the tweet to reply to - <code>content</code> (str): The content of the reply tweet</p> <p>Returns: String confirming reply was submitted with the tweet ID</p>"},{"location":"skills/uniswap/","title":"Uniswap","text":"<p>An example skill is the UniswapSkill, which allows for interacting with the Uniswap protocol.</p> <p>The Uniswap skill currently consists of two tools:</p> <ul> <li><code>get_price</code>: Get the price of a token in USD</li> <li><code>swap</code>: Swap an exact amount of ETH for tokens</li> </ul> <p>The <code>get_price</code> tool can be used to get the price of a token in terms of another token on Uniswap V2. It takes the following parameters:</p> <ul> <li><code>network</code>: The network to query the price on. Can be one of: \"ethereum\", \"arbitrum\", or \"base\"</li> <li><code>token_in</code>: The address of the token you want to swap from</li> <li><code>token_out</code>: The address of the token you want to swap to</li> </ul> <p>The tool returns the price as a JSON string containing a \"price\" field with the numeric price value.</p> <p>The <code>swap</code> tool can be used to swap tokens on Uniswap V2. It supports three types of swaps:</p> <ul> <li>ETH to tokens</li> <li>Tokens to ETH</li> <li>Tokens to tokens</li> </ul> <p>The tool takes the following parameters:</p> <ul> <li><code>network</code>: The network to execute the swap on (\"ethereum\", \"arbitrum\", or \"base\")</li> <li><code>input_token</code>: The address of the token to swap from. Use <code>None</code> if swapping from ETH</li> <li><code>output_token</code>: The address of the token to swap to. Use <code>None</code> if swapping to ETH</li> <li><code>amount_in</code>: The amount of input tokens to swap</li> <li><code>recipient</code>: The address that will receive the output tokens</li> <li><code>slippage</code>: The maximum acceptable slippage percentage (e.g. 0.05 for 5%)</li> <li><code>deadline</code>: Optional Unix timestamp deadline for the swap. If not provided, defaults to 1 minute from now</li> </ul> <p>The tool returns the transaction hash of the executed swap.</p>"}]}